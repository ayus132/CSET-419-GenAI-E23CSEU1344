{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBRx2heeTuL1",
        "outputId": "60f45af4-7d03-486d-8410-bb6382e5397c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Result: artificial intellig     aaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# 1. THE DATA: Our raw training text\n",
        "text = \"\"\"artificial intelligence is transforming modern society. it is used in healthcare.\n",
        "machine learning allows systems to improve automatically. data plays a critical role.\"\"\"\n",
        "text = text.lower()\n",
        "\n",
        "# 2. TOKENIZATION: Map characters to numbers so the computer can \"read\" them\n",
        "chars = sorted(list(set(text))) # Get unique letters/symbols\n",
        "char_to_idx = {char: i for i, char in enumerate(chars)}\n",
        "idx_to_char = {i: char for i, char in enumerate(chars)}\n",
        "\n",
        "# 3. SEQUENCING: Cut the text into \"slices\" (Input = 40 chars, Output = the next 1 char)\n",
        "seq_length = 20\n",
        "input_data = []\n",
        "output_data = []\n",
        "\n",
        "for i in range(0, len(text) - seq_length):\n",
        "    input_data.append([char_to_idx[c] for c in text[i : i + seq_length]])\n",
        "    output_data.append(char_to_idx[text[i + seq_length]])\n",
        "\n",
        "# Reshape data to fit the model [Samples, Time Steps, Features]\n",
        "X = np.reshape(input_data, (len(input_data), seq_length, 1)) / float(len(chars))\n",
        "y = tf.keras.utils.to_categorical(output_data)\n",
        "\n",
        "# 4. THE BRAIN (LSTM): Building the layers\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(X.shape[1], X.shape[2])), # Memory layer\n",
        "    Dense(y.shape[1], activation='softmax')           # Decision layer\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# 5. TRAINING: The model reads the text 50 times to learn patterns\n",
        "model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# 6. GENERATION: Start with a \"seed\" and let the model finish the sentence\n",
        "seed = \"artificial intellig \" # Added a space to make it seq_length (20) characters long\n",
        "generated_text = seed\n",
        "\n",
        "for i in range(50):\n",
        "    # Prepare the seed\n",
        "    x_input = np.reshape([char_to_idx[c] for c in seed[-seq_length:]], (1, seq_length, 1)) / float(len(chars))\n",
        "    # Predict the next letter\n",
        "    prediction = model.predict(x_input, verbose=0)\n",
        "    next_idx = np.argmax(prediction)\n",
        "    # Add to the text\n",
        "    seed += idx_to_char[next_idx]\n",
        "    generated_text += idx_to_char[next_idx]\n",
        "\n",
        "print(f\"Generated Result: {generated_text}\")"
      ]
    }
  ]
}